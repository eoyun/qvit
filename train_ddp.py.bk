import os
import pandas as pd
from PIL import Image
from sklearn.model_selection import train_test_split
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

import argparse

import string
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

parser = argparse.ArgumentParser()

parser.add_argument("--n_q_ffn",type=int,default=4,help='the number of qubits on FFN')
parser.add_argument("--n_q_mha",type=int,default=4,help='the number of qubits on MHA')
parser.add_argument("--embed",type=int,default=4,help='embed dimension')
parser.add_argument("--ffn_dim",type=int,default=4,help='ffn dimension')
parser.add_argument("--n_layer",type=int,default=1,help='the number of qubit layer')
parser.add_argument("--epochs",type=int,default=20,help='the number of epochs')
parser.add_argument("--label",type=str,default="",help="label the output name")

args = parser.parse_args()
# Configuration
image_size = 98  # e.g., 98 (must be divisible by patch_size)
patch_size = 14  # e.g., 7
embed_dim =  args.embed# Transformer embedding dimension (must equal n_qubits_transformer for quantum attention)
num_heads = 2
num_blocks = 2
ffn_dim = args.ffn_dim
n_qubits_transformer = args.n_q_mha
n_qubits_ffn = args.n_q_ffn
n_qlayers = args.n_layer
q_device = "lightning.gpu"  # Quantum device (e.g., default.qubit, braket.qubit, etc.)

dropout = 0.0
epochs = args.epochs
batch_size = 16
learning_rate = 1e-5
label = args.label

print(f"{epochs} : epochs")
print(f"{embed_dim} : embed_dim")
print(f"{n_qlayers} : n_qlayers")
print(f"{n_qubits_transformer} : n_qubits_transformer")
print(f"{n_qubits_ffn} : n_qubits_ffn")


df = pd.read_csv('rm_invalid.csv')

df = df.sample(frac=1).reset_index(drop=True)
df_mergedHard   = df[df['Label'] == 'mergedHard'].iloc[:1000]
df_notMerged    = df[df['Label'] == 'notMerged'].iloc[:1000]
df_notElectron  = df[df['Label'] == 'notElectron'].iloc[:1000]
df_limited = pd.concat([df_mergedHard, df_notMerged, df_notElectron], ignore_index=True)
df_limited = df_limited.sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle

# Prepare label mapping
labels = sorted(df_limited['Label'].unique().tolist())  # sorted unique labels
label_to_idx = {label: idx for idx, label in enumerate(labels)}
idx_to_label = {idx: label for label, idx in label_to_idx.items()}
num_classes = len(labels)
print("Classes:", labels)  # e.g., ['mergedHard', 'notElectron', 'notMerged']

df_limited['LabelIdx'] = df_limited['Label'].map(label_to_idx)

X = df_limited['ImagePath'].values
y = df_limited['LabelIdx'].values
# First split off 20% as test, then split the remaining 80% equally into train/val
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, 
    random_state=42, stratify=y)
X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, 
    random_state=42, stratify=y_temp)
print(f"Train size: {len(X_train)}, Val size: {len(X_val)}, Test size: {len(X_test)}")

# Data transformations and augmentation
train_transforms = transforms.Compose([
    transforms.Resize((image_size, image_size), interpolation=transforms.InterpolationMode.BICUBIC),
    ## Random Zoom Out or In
    #transforms.RandomApply([
    #    transforms.RandomChoice([
    #        transforms.RandomAffine(degrees=0, scale=(0.6, 0.9), fill=0),  # zoom out
    #        transforms.RandomAffine(degrees=0, scale=(1.1, 1.4), fill=0)   # zoom in
    #    ])
    #], p=0.5),
    ## Random Rotation (±72° max)
    #transforms.RandomApply([transforms.RandomRotation(degrees=72)], p=0.5),
    ## Random Brightness
    #transforms.RandomApply([transforms.ColorJitter(brightness=0.2)], p=0.5),
    ## Random Contrast
    #transforms.RandomApply([transforms.ColorJitter(contrast=0.2)], p=0.5),
    ## Random Shear (~20°)
    #transforms.RandomApply([transforms.RandomAffine(degrees=0, shear=20, fill=0)], p=0.5),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Transforms for validation/test (no augmentation)
test_transforms = transforms.Compose([
    transforms.Resize((image_size, image_size), interpolation=transforms.InterpolationMode.BICUBIC),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

class ImageDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels  # numeric labels
        self.transform = transform
    def __len__(self):
        return len(self.image_paths)
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        # Open image (ensure 3 channels)
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, label

dist.init_process_group(backend="nccl", init_method="env://")

local_rank = int(os.environ["LOCAL_RANK"])
torch.cuda.set_device(local_rank)
# Create Dataset instances
train_dataset = ImageDataset(X_train, y_train, transform=train_transforms)
val_dataset   = ImageDataset(X_val,   y_val,   transform=test_transforms)
test_dataset  = ImageDataset(X_test,  y_test,  transform=test_transforms)

train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, sampler=train_sampler)
val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2, sampler=val_sampler)
test_loader  = DataLoader(test_dataset,  batch_size=batch_size*2, shuffle=False, num_workers=2)

import torch.nn as nn
from qvit import VisionTransformer

# Instantiate the Vision Transformer model
#device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#print(device)
#print("####################")
#print(torch.cuda.is_available())

model = VisionTransformer(
    image_size=image_size,
    patch_size=patch_size,
    in_channels=3,
    embed_dim=embed_dim,
    num_heads=num_heads,
    num_blocks=num_blocks,
    num_classes=num_classes,
    ffn_dim=ffn_dim,
    n_qubits_transformer=n_qubits_transformer,
    n_qubits_ffn=n_qubits_ffn,
    n_qlayers=n_qlayers,
    dropout=dropout,
    q_device=q_device
)
print(model)
model.to(local_rank)
ddp_model = DDP(model, device_ids=[local_rank])

from sklearn.metrics import f1_score
import torch.optim as optim
from torch.cuda.amp import autocast, GradScaler

# Define focal loss function
def focal_loss(inputs, targets, alpha=0.25, gamma=2.0, reduction='mean'):
    """
    Compute the focal loss between `inputs` (logits) and `targets` (integer class indices).
    """
    # Standard cross-entropy (not averaged, per-sample)
    ce_loss = torch.nn.functional.cross_entropy(inputs, targets, reduction='none')
    # p_t: probability of the true class for each sample
    p_t = torch.exp(-ce_loss)
    # Focal loss computation
    loss = alpha * ((1 - p_t) ** gamma) * ce_loss
    if reduction == 'mean':
        return loss.mean()
    elif reduction == 'sum':
        return loss.sum()
    else:
        return loss

# Instantiate optimizer (AdamW)
optimizer = optim.AdamW(ddp_model.parameters(), lr=learning_rate)

# Learning rate scheduler: ReduceLROnPlateau (monitor val F1)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.8, patience=3)

# Early stopping parameters
patience = 100
best_val_f1 = -float('inf')
epochs_no_improve = 0

# Mixed precision setup
scaler = GradScaler()

import numpy as np

metrics_history = {
    "train_loss": [], "val_loss": [],
    "train_f1": [], "val_f1": []
}
#best_model_path = f"/pscratch/sd/e/eoyun/4l/ckpts/pytorch/quantum_{pd.Timestamp.now():%Y%m%d_%H%M}/best_model.pth"
best_model_path = f"/pscratch/sd/e/eoyun/4l/ckpts/pytorch/quantum_ddp/{epochs}_epochs_{n_qubits_ffn}_qubitOnFFN_{n_qubits_transformer}_qubitOnMHA_{n_qlayers}_qubitLayer_{embed_dim}_embedDimension_{label}/best_model.pth"
os.makedirs(os.path.dirname(best_model_path), exist_ok=True)
results_dir = f"/pscratch/sd/e/eoyun/4l/results/pytorch/quantum_ddp/{epochs}_epochs_{n_qubits_ffn}_qubitOnFFN_{n_qubits_transformer}_qubitOnMHA_{n_qlayers}_qubitLayer_{embed_dim}_embedDimension_{label}"
os.makedirs(results_dir, exist_ok=True)

# --- 앞부분 공통 유틸 추가 ---------------------------------------------------- # NEW
def is_dist():
    return dist.is_available() and dist.is_initialized()

def get_rank():
    return dist.get_rank() if is_dist() else 0

def get_world_size():
    return dist.get_world_size() if is_dist() else 1

def reduce_mean_scalar(x: float) -> float:  # NEW: 스칼라 평균 집계
    if not is_dist(): 
        return float(x)
    t = torch.tensor([x], dtype=torch.float32, device=torch.cuda.current_device())
    dist.all_reduce(t, op=dist.ReduceOp.SUM)
    return float((t / get_world_size()).item())

def all_gather_numpy_1d(arr_np: np.ndarray, device) -> np.ndarray:  # NEW: 가변 길이 all_gather
    if not is_dist():
        return arr_np
    t = torch.as_tensor(arr_np, device=device)  # 1D
    l = torch.tensor([t.numel()], device=device, dtype=torch.int64)
    ls = [torch.zeros_like(l) for _ in range(get_world_size())]
    dist.all_gather(ls, l)
    maxlen = int(torch.stack(ls).max().item())
    pad = torch.zeros(maxlen, dtype=t.dtype, device=device)
    pad[:t.numel()] = t
    outs = [torch.zeros_like(pad) for _ in range(get_world_size())]
    dist.all_gather(outs, pad)
    outs_trim = []
    for out, li in zip(outs, ls):
        outs_trim.append(out[: int(li.item())].clone())
    return torch.cat(outs_trim, dim=0).detach().cpu().numpy()

def bcast_float(x: float) -> float:  # NEW: rank0 스칼라 브로드캐스트
    if not is_dist():
        return float(x)
    t = torch.tensor([x], dtype=torch.float32, device=torch.cuda.current_device())
    dist.broadcast(t, src=0)
    return float(t.item())

def bcast_bool(flag: bool) -> bool:  # NEW
    if not is_dist():
        return bool(flag)
    t = torch.tensor([1 if flag else 0], dtype=torch.int32, device=torch.cuda.current_device())
    dist.broadcast(t, src=0)
    return bool(int(t.item()))
# -----------------------------------------------------------------------------

for epoch in range(1, epochs+1):
    # Training
    train_sampler.set_epoch(epoch)
    model.train()
    train_losses = []
    all_train_preds = []
    all_train_labels = []

    for images, labels in train_loader:
        images = images.to(local_rank)
        labels = labels.to(local_rank)
        optimizer.zero_grad()
        with autocast():
            logits = ddp_model(images)
            loss = focal_loss(logits, labels)
        train_losses.append(loss.item())
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        preds = logits.argmax(dim=1)
        all_train_preds.append(preds.detach().cpu().numpy())
        all_train_labels.append(labels.detach().cpu().numpy())

    # --- 집계: 각 rank의 로컬 값 -> 전역으로 합치기 --------------------------- # CHANGED
    # loss는 평균을 all_reduce로 통일
    train_loss_local = float(np.mean(train_losses)) if len(train_losses) else 0.0
    train_loss = reduce_mean_scalar(train_loss_local)  # NEW

    # F1은 전체 예측/라벨을 모아 rank0에서만 계산
    train_preds_np_local = np.concatenate(all_train_preds) if all_train_preds else np.array([], dtype=np.int64)
    train_labels_np_local = np.concatenate(all_train_labels) if all_train_labels else np.array([], dtype=np.int64)
    # GPU 장치에 올려 all_gather 변장
    train_preds_all = all_gather_numpy_1d(train_preds_np_local, device=images.device)   # NEW
    train_labels_all = all_gather_numpy_1d(train_labels_np_local, device=images.device) # NEW

    if get_rank() == 0:  # NEW: rank0만 전역 F1 계산
        train_f1 = f1_score(train_labels_all, train_preds_all, average='macro')
    else:
        train_f1 = 0.0
    train_f1 = bcast_float(train_f1)  # NEW: 모든 rank에 동일 값 배포
    # -------------------------------------------------------------------------

    # Validation
    model.eval()
    val_losses = []
    all_val_preds = []
    all_val_labels = []
    val_sampler.set_epoch(epoch)

    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(local_rank)
            labels = labels.to(local_rank)
            with autocast():
                logits = ddp_model(images)
                loss = focal_loss(logits, labels)
            val_losses.append(loss.item())
            preds = logits.argmax(dim=1)
            all_val_preds.append(preds.cpu().numpy())
            all_val_labels.append(labels.cpu().numpy())

    # --- 검증 집계 ------------------------------------------------------------ # CHANGED
    val_loss_local = float(np.mean(val_losses)) if len(val_losses) else 0.0
    val_loss = reduce_mean_scalar(val_loss_local)  # NEW

    val_preds_np_local = np.concatenate(all_val_preds) if all_val_preds else np.array([], dtype=np.int64)
    val_labels_np_local = np.concatenate(all_val_labels) if all_val_labels else np.array([], dtype=np.int64)

    val_preds_all = all_gather_numpy_1d(val_preds_np_local, device=torch.cuda.current_device())  # NEW
    val_labels_all = all_gather_numpy_1d(val_labels_np_local, device=torch.cuda.current_device()) # NEW

    if get_rank() == 0:  # NEW
        val_f1 = f1_score(val_labels_all, val_preds_all, average='macro')
    else:
        val_f1 = 0.0
    val_f1 = bcast_float(val_f1)  # NEW
    # -------------------------------------------------------------------------

    # Record metrics  # CHANGED: 모든 rank가 동일 벡터를 유지하고 싶으면 아래 유지, 아니면 rank0만 기록
    if get_rank() == 0:  # NEW: 중복 기록 방지
        metrics_history["train_loss"].append(train_loss)
        metrics_history["val_loss"].append(val_loss)
        metrics_history["train_f1"].append(train_f1)
        metrics_history["val_f1"].append(val_f1)

    # Print epoch results  # CHANGED: rank0만 출력
    if get_rank() == 0:  # NEW
        print(f"Epoch {epoch:03d}: Train Loss={train_loss:.4f}, Train F1={train_f1:.4f} | "
              f"Val Loss={val_loss:.4f}, Val F1={val_f1:.4f}")

    # LR scheduling step  # CHANGED: 모든 rank가 동일한 입력을 쓰므로 어디서든 가능. 관례상 rank0에서만 호출 후 필요하면 브로드캐스트
    if get_rank() == 0:  # NEW
        scheduler.step(val_f1)
    _ = bcast_float(val_f1)  # NO-OP 동기화용 선택 사항

    # Early stopping + Save best  # CHANGED: rank0만 판단·저장, 플래그만 브로드캐스트
    if get_rank() == 0:  # NEW
        improved = val_f1 > best_val_f1
    else:
        improved = False
    improved = bcast_bool(improved)  # NEW

    if get_rank() == 0 and improved:  # NEW
        best_val_f1 = val_f1
        epochs_no_improve = 0
        torch.save({
            "epoch": epoch,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "loss": loss,
        }, best_model_path)
        best_epoch = epoch
    elif get_rank() == 0 and not improved:  # NEW
        epochs_no_improve += 1
        if epochs_no_improve >= patience:
            print(f"No improvement for {patience} epochs. Early stopping at epoch {epoch}.")
            early_stop = True
        else:
            early_stop = False
    else:
        early_stop = False
    early_stop = bcast_bool(early_stop)  # NEW
    if early_stop:
        break

    # Plotting  # CHANGED: rank0만 그림 저장
    if get_rank() == 0:  # NEW
        epochs_range = range(1, len(metrics_history["train_loss"]) + 1)
        plt.figure(figsize=(12,5))
        plt.subplot(1,2,1)
        plt.plot(epochs_range, metrics_history["train_loss"], label="Train Loss")
        plt.plot(epochs_range, metrics_history["val_loss"], label="Val Loss")
        plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.title("Loss vs Epochs"); plt.legend()

        plt.subplot(1,2,2)
        plt.plot(epochs_range, metrics_history["train_f1"], label="Train F1")
        plt.plot(epochs_range, metrics_history["val_f1"], label="Val F1")
        plt.xlabel("Epoch"); plt.ylabel("F1 Score"); plt.title("F1 Score vs Epochs"); plt.legend()

        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, f"training_history_{epoch}.png"))

print(f"Best model was from epoch {best_epoch} with Val F1 = {best_val_f1:.4f}")

dist.destroy_process_group()
# Load the best model for testing
ckpt = torch.load(best_model_path)
best_model = VisionTransformer(
    image_size=image_size,
    patch_size=patch_size,
    in_channels=3,
    embed_dim=embed_dim,
    num_heads=num_heads,
    num_blocks=num_blocks,
    num_classes=num_classes,
    ffn_dim=ffn_dim,
    n_qubits_transformer=n_qubits_transformer,
    n_qubits_ffn=n_qubits_ffn,
    n_qlayers=n_qlayers,
    dropout=dropout,
    q_device=q_device
)
best_model.load_state_dict(ckpt["model_state_dict"])
best_model.to(device)
best_model.eval()

# Get predictions on the test set
y_true = []
y_prob = []  # probabilities for each class
with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        logits = best_model(images)
        probs = torch.softmax(logits, dim=1)
        y_true.extend(labels.cpu().numpy().tolist())
        y_prob.extend(probs.cpu().numpy().tolist())

y_true = np.array(y_true)
y_prob = np.array(y_prob)  # shape (n_samples, num_classes)

# Determine predicted class indices
y_pred_indices = np.argmax(y_prob, axis=1)
# Map indices to label names
y_pred_labels = [idx_to_label[idx] for idx in y_pred_indices]
y_true_labels = [idx_to_label[idx] for idx in y_true]

# Save predictions to CSV
df_submission = pd.DataFrame({"pred": y_pred_labels, "true": y_true_labels})
df_submission.to_csv(os.path.join(results_dir, "predictions.csv"), index=False)
print("Saved test predictions to CSV.")

# Plot training history (Loss and F1 over epochs)
epochs_range = range(1, len(metrics_history["train_loss"]) + 1)
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(epochs_range, metrics_history["train_loss"], label="Train Loss")
plt.plot(epochs_range, metrics_history["val_loss"], label="Val Loss")
plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.title("Loss vs Epochs"); plt.legend()

plt.subplot(1,2,2)
plt.plot(epochs_range, metrics_history["train_f1"], label="Train F1")
plt.plot(epochs_range, metrics_history["val_f1"], label="Val F1")
plt.xlabel("Epoch"); plt.ylabel("F1 Score"); plt.title("F1 Score vs Epochs"); plt.legend()

plt.tight_layout()
plt.savefig(os.path.join(results_dir, "training_history.png"))
#plt.show()

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
import numpy as np
import matplotlib.pyplot as plt

# 1) Check shapes
assert y_prob.ndim == 2, f"y_prob shape weird: {y_prob.shape}"
assert len(y_true) == y_prob.shape[0], f"len(y_true)={len(y_true)} vs y_prob={y_prob.shape}"

# 2) Class names
num_classes = y_prob.shape[1]
class_indices = list(range(num_classes))
try:
    class_names = [idx_to_label[i] for i in class_indices]
except Exception:
    class_names = [f"class_{i}" for i in class_indices]

# 3) Binarize
y_true_bin = label_binarize(y_true, classes=class_indices)  # shape: (N, num_classes)

# 4) Plot ROC (skip if one class)
plt.figure(figsize=(6, 6))
any_plotted = False
for i, name in enumerate(class_names):
    y_true_i = y_true_bin[:, i]
    # Skip if only one class in true labels
    if y_true_i.max() == 0 or y_true_i.min() == 1:
        print(f"[ROC] Skip '{name}': only one class present in y_true for this label.")
        continue
    fpr, tpr, _ = roc_curve(y_true_i, y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")
    any_plotted = True

plt.plot([0, 1], [0, 1], "k--")
plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate"); plt.ylabel("True Positive Rate")
plt.title("Multi-Class ROC Curve")
if any_plotted:
    plt.legend(loc="lower right")
else:
    plt.legend([], frameon=False)
plt.savefig(os.path.join(results_dir, "roc_curve.png"))
#plt.show()

